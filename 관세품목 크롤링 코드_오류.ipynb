{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XFzZwniHvwk6",
        "outputId": "22d60198-8b3b-4c0b-cde1-bd17c99f7b11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver_manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (2024.8.30)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, webdriver_manager\n",
            "Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4 webdriver_manager\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
        "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver\n",
        "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium"
      ],
      "metadata": {
        "id": "wZ59rJydwTS9",
        "outputId": "07f1bf9e-9b69-4220-df35-e977413ecc0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [2 InRelease 38.8 kB/128 kB 30%] [3 InRelease 69.2 kB/129 kB 54%] [Connected\u001b[0m\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [2 InRelease 62.0 kB/128 kB 48%] [3 InRelease 114 kB/129 kB 88%] [Connected \u001b[0m\u001b[33m\r0% [2 InRelease 75.0 kB/128 kB 59%] [Connected to r2u.stat.illinois.edu (192.17\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \u001b[0m\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \u001b[0m\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,192 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,626 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,531 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
            "Fetched 18.0 MB in 7s (2,477 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.19).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n",
            "--2024-12-09 00:55:33--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 91.189.91.82, 91.189.91.83, 185.125.190.83, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|91.189.91.82|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libu2f-udev_1.1.4-1_all.deb’\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-09 00:55:33 (366 MB/s) - ‘libu2f-udev_1.1.4-1_all.deb’ saved [3708/3708]\n",
            "\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-12-09 00:55:34--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 142.251.107.190, 142.251.107.136, 142.251.107.93, ...\n",
            "Connecting to dl.google.com (dl.google.com)|142.251.107.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 112377704 (107M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 107.17M   209MB/s    in 0.5s    \n",
            "\n",
            "2024-12-09 00:55:34 (209 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [112377704/112377704]\n",
            "\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 123636 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (131.0.6778.108-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-12-09 00:55:50--  https://chromedriver.storage.googleapis.com/114.0.5735.90/chromedriver_linux64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 142.251.107.207, 74.125.196.207, 74.125.141.207, ...\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|142.251.107.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7407250 (7.1M) [application/zip]\n",
            "Saving to: ‘/tmp/chromedriver_linux64.zip’\n",
            "\n",
            "chromedriver_linux6 100%[===================>]   7.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-12-09 00:55:50 (227 MB/s) - ‘/tmp/chromedriver_linux64.zip’ saved [7407250/7407250]\n",
            "\n",
            "Archive:  /tmp/chromedriver_linux64.zip\n",
            "  inflating: /tmp/chromedriver       \n",
            "  inflating: /tmp/LICENSE.chromedriver  \n",
            "Collecting selenium\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.27.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "\n",
        "# (최초 1회)\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver\n",
        "!pip install chromedriver-autoinstaller"
      ],
      "metadata": {
        "id": "a7cgwJLkwU5m",
        "outputId": "37f76729-9b2d-4f0d-8cdd-83b47440ecb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " chromium-chromedriver : Depends: chromium-browser (>= 1:85.0.4183.83-0ubuntu2.22.04.1) but it is not going to be installed\n",
            " google-chrome-stable : Depends: libvulkan1 but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "cp: missing destination file operand after '/usr/lib/chromium-browser/chromedriver'\n",
            "Try 'cp --help' for more information.\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver-autoinstaller) (24.2)\n",
            "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: chromedriver-autoinstaller\n",
            "Successfully installed chromedriver-autoinstaller-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import chromedriver_autoinstaller  # setup chrome options\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import urllib.request\n",
        "from urllib.request import urlretrieve"
      ],
      "metadata": {
        "id": "vAKlsVmVwa-C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chrome_path = \"/usr/lib/chromium-browser/chromedriver\""
      ],
      "metadata": {
        "id": "jCZuEB3vxQ_G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.insert(0,chrome_path)\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # ensure GUI is off\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # set path to chromedriver as per your configuration\n",
        "chrome_options.add_argument('lang=ko_KR') # 한국어\n",
        "\n",
        "chromedriver_autoinstaller.install()  # set the target URL\n",
        "\n",
        "# 크롬 드라이버 생성\n",
        "driver = webdriver.Chrome(options=chrome_options)"
      ],
      "metadata": {
        "id": "ZfL_BV-FxPbQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Z1K2ftR_vwlD",
        "outputId": "ebe5cbb7-a649-4c78-d753-07869d17e763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/135 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/135 [00:11<26:09, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 2/135 [00:23<25:37, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/135 [00:37<28:26, 12.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 4/135 [00:49<27:03, 12.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 5/135 [01:01<26:19, 12.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 6/135 [01:12<25:47, 12.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 7/135 [01:24<25:11, 11.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 8/135 [01:35<24:50, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 9/135 [01:47<24:33, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 10/135 [01:59<24:21, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 11...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 10/135 [02:07<26:33, 12.74s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-50947042dfc0>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arguments[0].click();\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtl_element\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use JavaScript click to avoid staleness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait for the leftArea and rightArea to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# Extract text from leftArea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# 페이지 열기\n",
        "url = \"https://unipass.customs.go.kr/clip/index.do\"\n",
        "driver.get(url)\n",
        "\n",
        "# JavaScript가 실행될 시간을 기다리기\n",
        "driver.implicitly_wait(10)  # 최대 10초 대기\n",
        "\n",
        "# 페이지의 HTML 가져오기\n",
        "# soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "# 세계HS 창을 찾아 click_box 변수에 저장 (By.CLASS_NAME 방식)\n",
        "click_box = driver.find_element(By.CLASS_NAME,\"M_ULS0200000000\")\n",
        "click_box.click()\n",
        "\n",
        "# HS해설서 창을 찾아 click_box 변수에 저장 (By.CLASS_NAME 방식)\n",
        "click_box = driver.find_element(By.XPATH, '//*[@id=\"LEFTMENU_LNK_UI-ULS-0202-001Q\"]/span')\n",
        "click_box.click()\n",
        "\n",
        "# 조회 창을 찾아 click_box 변수에 저장 (By.XPATH 방식)\n",
        "click_box = driver.find_element(By.XPATH, '//*[@id=\"searchVo\"]/div[2]/footer/button/span')\n",
        "driver.execute_script(\"arguments[0].click();\", click_box)\n",
        "\n",
        "\n",
        "# Wait for the table to load\n",
        "time.sleep(1)  # Adjust the wait time as needed\n",
        "\n",
        "# Locate the table\n",
        "table = driver.find_element(By.XPATH, '//*[@id=\"ULS0202001Q_T1_table1\"]/tbody')\n",
        "\n",
        "# Parse the table HTML using BeautifulSoup\n",
        "soup = BeautifulSoup(table.get_attribute(\"outerHTML\"), 'html.parser')\n",
        "\n",
        "# Extract table rows\n",
        "rows = soup.find_all('tr')\n",
        "\n",
        "# Initialize an empty DataFrame\n",
        "data = pd.DataFrame(columns=[\"구분\", \"년도\", \"단위\", \"HS분류\", \"내용\", \"Left Area\", \"Right Area\"])\n",
        "\n",
        "# # Iterate through the rows and extract data\n",
        "# for row in rows:\n",
        "#     cols = row.find_all('td')\n",
        "#     cols = [col.text.strip() for col in cols]  # Extract text and clean up whitespace\n",
        "#     if cols:  # Check if the row has data\n",
        "#         # Click on the `dtlInfo` link\n",
        "#         dtl_link = row.find('a', class_='dtlInfo')\n",
        "#         if dtl_link:\n",
        "#             dtl_element = driver.find_element(By.LINK_TEXT, dtl_link.text)\n",
        "#             dtl_element.click()\n",
        "#             time.sleep(2)  # Wait for the leftArea and rightArea to load\n",
        "\n",
        "#             # Extract text from leftArea\n",
        "#             left_area = driver.find_element(By.ID, 'divLft_tab4')\n",
        "#             left_area_text = left_area.text.strip()\n",
        "\n",
        "#             # Extract text from rightArea\n",
        "#             right_area = driver.find_element(By.ID, 'divRght_tab4')\n",
        "#             right_area_text = right_area.text.strip()\n",
        "\n",
        "#             # Go back to the main page to continue scraping\n",
        "#             # driver.back()\n",
        "#             time.sleep(2)  # Wait for the page to load\n",
        "\n",
        "#             # Add data to the DataFrame\n",
        "#             data.loc[len(data)] = cols + [left_area_text, right_area_text]\n",
        "\n",
        "# Loop through all 135 pages\n",
        "for page in tqdm(range(1, 136)):\n",
        "    print(f\"Processing page {page}...\")\n",
        "\n",
        "    # Locate the table\n",
        "    table = driver.find_element(By.XPATH, '//*[@id=\"ULS0202001Q_T1_table1\"]/tbody')\n",
        "\n",
        "    # Parse the table HTML using BeautifulSoup\n",
        "    soup = BeautifulSoup(table.get_attribute(\"outerHTML\"), 'html.parser')\n",
        "\n",
        "    # Extract table rows\n",
        "    rows = soup.find_all('tr')\n",
        "\n",
        "    # Iterate through the rows and extract data\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')\n",
        "        cols = [col.text.strip() for col in cols]  # Extract text and clean up whitespace\n",
        "        if cols:  # Check if the row has data\n",
        "            # <td class=\"ellipsis\" title=\"류\"> 요소 찾기\n",
        "            element = row.find('td', class_='ellipsis', title=True)\n",
        "            dtl_link = row.find('a', class_='dtlInfo')\n",
        "\n",
        "            # 조건 확인 및 처리\n",
        "            if element and element['title'] == '류':\n",
        "                dtl_element=driver.find_element(By.XPATH, f\"//a[text()='{dtl_link.text.strip()}']\")\n",
        "\n",
        "            else:\n",
        "                # Click on the `dtlInfo` link\n",
        "                dtl_element = driver.find_element(By.LINK_TEXT, dtl_link.text)\n",
        "\n",
        "            driver.execute_script(\"arguments[0].click();\", dtl_element)  # Use JavaScript click to avoid staleness\n",
        "            time.sleep(0.8)  # Wait for the leftArea and rightArea to load\n",
        "\n",
        "            # Extract text from leftArea\n",
        "            left_area = driver.find_element(By.ID, 'divLft_tab4')\n",
        "            left_area_text = left_area.text.strip()\n",
        "\n",
        "            # Extract text from rightArea\n",
        "            right_area = driver.find_element(By.ID, 'divRght_tab4')\n",
        "            right_area_text = right_area.text.strip()\n",
        "\n",
        "            # Add data to the DataFrame\n",
        "            data.loc[len(data)] = cols + [left_area_text, right_area_text]\n",
        "\n",
        "    # Navigate to the next page\n",
        "    try:\n",
        "        wait=WebDriverWait(driver, 10)\n",
        "        next_page = wait.until(EC.element_to_be_clickable((By.XPATH, f'//div[@class=\"paging\"]//a[@href=\"#{page + 1}\"]')))\n",
        "        driver.execute_script(\"arguments[0].click();\", next_page)\n",
        "        time.sleep(2)  # Wait for the page to load\n",
        "    except Exception as e:\n",
        "        print(f\"Could not navigate to page {page + 1}: {e}\")\n",
        "        break\n",
        "\n",
        "# Display the DataFrame\n",
        "\n",
        "# Save the data to a CSV file\n",
        "data.to_csv('HSdescription_data.csv', index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgLVx2zWDbPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}